#!/bin/bash

# Inspired by https://github.com/KranthiGV/Pretrained-Show-and-Tell-model

# JPEG image file to caption.
IMAGE_FILE="./sample-images/$1"

echo "Captioning image $IMAGE_FILE"

# Path to checkpoint file.
CHECKPOINT_PATH="./model.ckpt-2000000"

# Vocabulary file generated by the preprocessing script.
# Since the tokenizer could be of a different version, use the word_counts.txt file supplied. 
VOCAB_FILE="./word_counts.txt"

# Build the inference binary.
bazel build -c opt im2txt/run_inference

# Run inference to generate captions.
bazel-bin/im2txt/run_inference \
  --checkpoint_path=${CHECKPOINT_PATH} \
  --vocab_file=${VOCAB_FILE} \
  --input_files=${IMAGE_FILE}